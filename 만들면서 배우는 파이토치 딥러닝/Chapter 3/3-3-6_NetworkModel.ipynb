{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPHWZEZE2GrNU4cfAmCs/CD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZvbpfbl4eiD","executionInfo":{"status":"ok","timestamp":1664168789922,"user_tz":-540,"elapsed":4229,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"749b4fdc-57f7-436d-8c42-9573b0d5e552"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pytorch_advanced'...\n","remote: Enumerating objects: 548, done.\u001b[K\n","remote: Counting objects: 100% (174/174), done.\u001b[K\n","remote: Compressing objects: 100% (173/173), done.\u001b[K\n","remote: Total 548 (delta 5), reused 162 (delta 0), pack-reused 374\u001b[K\n","Receiving objects: 100% (548/548), 50.13 MiB | 29.30 MiB/s, done.\n","Resolving deltas: 100% (43/43), done.\n"]}],"source":["!git clone https://github.com/Rope-player/pytorch_advanced.git"]},{"cell_type":"code","source":["%cd \"pytorch_advanced\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QwN7tBU55-4h","executionInfo":{"status":"ok","timestamp":1664168789923,"user_tz":-540,"elapsed":7,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"48a6a64e-76ad-47cf-88f2-cb58ef6860f2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/pytorch_advanced\n"]}]},{"cell_type":"code","source":["%cd \"3_semantic_segmentation\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pICz-SQ5-65","executionInfo":{"status":"ok","timestamp":1664168789923,"user_tz":-540,"elapsed":5,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"b647ef93-21fe-431a-90d0-f020f3f8ad43"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/pytorch_advanced/3_semantic_segmentation\n"]}]},{"cell_type":"code","source":["import os\n","import urllib.request\n","import zipfile\n","import tarfile"],"metadata":{"id":"0AYtZw5s5-9a","executionInfo":{"status":"ok","timestamp":1664168789923,"user_tz":-540,"elapsed":3,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_dir = \"./data/\"\n","if not os.path.exists(data_dir):\n","  os.mkdir(data_dir)"],"metadata":{"id":"V64vcpXm5_AZ","executionInfo":{"status":"ok","timestamp":1664168789923,"user_tz":-540,"elapsed":3,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["weights_dir = \"./weights/\"\n","if not os.path.exists(weights_dir):\n","  os.mkdir(weights_dir)"],"metadata":{"id":"8iKSPovE5_C5","executionInfo":{"status":"ok","timestamp":1664168789924,"user_tz":-540,"elapsed":4,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n","target_path = os.path.join(data_dir, \"VOCtrainval_11-May-2012.tar\") \n","\n","if not os.path.exists(target_path):\n","  urllib.request.urlretrieve(url, target_path)\n","    \n","  tar = tarfile.TarFile(target_path)  \n","  tar.extractall(data_dir)  \n","  tar.close()"],"metadata":{"id":"YUHOcT0Z5_Fh","executionInfo":{"status":"ok","timestamp":1664168900011,"user_tz":-540,"elapsed":110091,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"Dz03Vnd15_H5","executionInfo":{"status":"ok","timestamp":1664168902468,"user_tz":-540,"elapsed":2463,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# PSPNet 구성 및 구현"],"metadata":{"id":"Tb7RNpB96IIe"}},{"cell_type":"markdown","source":["PSPNet은 네 개의 모듈로 구성됨\n","- Feature\n","- Pyramid Pooling\n","- Decoder\n","- AuxLoss"],"metadata":{"id":"g8n01jze6Qxq"}},{"cell_type":"markdown","source":["### Feature"],"metadata":{"id":"Mz35OwAO609s"}},{"cell_type":"markdown","source":["Encoder 모듈러도 불림. 이 모듈은 입력 화상의 특징을 파악하는 것을 목적으로 함. 375 \\* 375 크기의 화상을 입력받으면 60 \\* 60 크기의 화상을 출력. 이때 2048개의 화상 특징을 파악한 채널을 준비해야 함."],"metadata":{"id":"3sLZ-He26_qj"}},{"cell_type":"markdown","source":["### Pyramid Pooling"],"metadata":{"id":"51E5HmvS7siz"}},{"cell_type":"markdown","source":["PSPNet의 독창성을 보여주는 모듈. \n","\n","픽셀의 라벨을 구하기위해 다양한 크기의 주변 정보를 요구함.\n","\n","예를 들어 하나의 픽셀로는 소의 등인지 말의 등인지 알 수가 없지만, 픽셀의 주위를 점진적으로 확대한 특징량을 보면 소인지 말인지 확인 할 수 있음. \n","\n","즉 픽셀의 물체 라벨을 구하려면 그 주변 뿐만 아니라 더 넓은 화상 정보가 필요함."],"metadata":{"id":"w_LTpcpB7usX"}},{"cell_type":"markdown","source":["크게 네 가지 크기의 특징맵을 준비함. \n","1. 화상 전체\n","2. 화상 절반\n","3. 화상의 1/3\n","4. 화상의 1/6\n","\n","출력데이터 크기는 4096 \\* 60 \\* 60임."],"metadata":{"id":"VNU9gxEq9f8k"}},{"cell_type":"markdown","source":["### Decoder"],"metadata":{"id":"As6k0MAd9ZDw"}},{"cell_type":"markdown","source":["업샘플링 모듈이라고도 함. Decoder의 목적은 두 가지임\n","\n","1. Pyramid Pooling의 출력을 21 \\* 60 \\* 60 텐서로 변환\n","2. 위의 텐서를 원 입력 화상 크기에 맞도록 21 \\* 475 \\* 475로 변환"],"metadata":{"id":"qLaaxZep9ZGH"}},{"cell_type":"markdown","source":["### AuxLoss"],"metadata":{"id":"xbE8Vj6s9ZLH"}},{"cell_type":"markdown","source":["원래라면 위 세 단계로 시맨틱 부날은 이루어지지만, PSPNet 에서는 파라미터의 학습을 효율적으로 하기 위해 AuxLoss 모듈을 준비함.\n","\n","이 모듈은 손실함수 계산을 보조함."],"metadata":{"id":"f1tmLjDj9ZNW"}},{"cell_type":"markdown","source":["학습시에는 AuxLoss의 출력돠 Decoder의 출력 모두 화상의 정답 정보로 대응시켜 손실값을 계산. 이후 손실 값에 따른 오차 역전파법을 실시하여 네트워크의 결합 파라미터를 갱신."],"metadata":{"id":"R73q_MH9_JXE"}},{"cell_type":"markdown","source":["AuxLoss는 Feature층의 중간까지 결과로 시맨틱 분할을 실시하여 분류 정확도는 떨어지나, 오차 역전파법 수행 시 Feature층의 중간까지의 네트워크 파라미터가 더 좋은 값이 되도록 도움."],"metadata":{"id":"ykilbWw3_XWR"}},{"cell_type":"markdown","source":["## PSPNet 클래스 구현"],"metadata":{"id":"D0_h78Rf_rVq"}},{"cell_type":"markdown","source":["PSPNet의 형태를 규정하는 파라미터 설정 인수로서 클래스만 취하고 나머지는 하드코딩할 것임. Feature 모듈은 다섯개의 서브 네트워크로 기타 모듈은 하나의 서브 네트워크로 구성.\n","- `feature_conv`\n","- `feature_res_1`\n","- `feature_res_2`\n","- `feature_dilated_res_1`\n","- `feature_dilated_res_2`"],"metadata":{"id":"ObnLcfCV_uTa"}},{"cell_type":"markdown","source":["PSPNet의 클래스 메소드는 forward 뿐임."],"metadata":{"id":"x1diXnlEAYWM"}},{"cell_type":"code","source":["class PSPNet(nn.Module):\n","  def __init__(self, n_classes):\n","    super(PSPNet, self).__init__()\n","\n","    # 파라미터 설정\n","    block_config = [3, 4, 6, 3]  # resnet50\n","    img_size = 475\n","    img_size_8 = 60              # img_size의 1/8로 설정\n","\n","    # 4개의 모듈을 구성하는 서브 네트워크 준비\n","    self.feature_conv = FeatureMap_convolution()\n","    self.feature_res_1 = ResidualBlockPSP(n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n","    self.feature_res_2 = ResidualBlockPSP(n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n","    self.feature_dilated_res_1 = ResidualBlockPSP(n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n","    self.feature_dilated_res_2 = ResidualBlockPSP(n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n","\n","    self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[6, 3, 2, 1], height=img_size_8, width=img_size_8)\n","    self.decode_feature = DecodePSPFeature(height=img_size, width=img_size, n_classes=n_classes)\n","    self.aux = AuxiliaryPSPlayers(in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n","\n","  def forward(self, x):\n","    x = self.feature_conv(x)\n","    x = self.feature_res_1(x)\n","    x = self.feature_res_2(x)\n","    x = self.feature_dilated_res_1(x)\n","\n","    output_aux = self.aux(x)  # Feature 모듈의 중간을 Aux 모듈로\n","\n","    x = self.feature_dilated_res_2(x)\n","\n","    x = self.pyramid_pooling(x)\n","    output = self.decode_feature(x)\n","\n","    return (output, output_aux)"],"metadata":{"id":"nEvvNXO66QNC","executionInfo":{"status":"ok","timestamp":1664168902468,"user_tz":-540,"elapsed":10,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Feature 모듈 설명 및 구현(ResNet)"],"metadata":{"id":"YPWAdqPmA779"}},{"cell_type":"markdown","source":["## Feature 모듈의 서브 네트워크 구성"],"metadata":{"id":"gai52vWSBGE0"}},{"cell_type":"markdown","source":["Feature 모듈은 다섯 개의 서브 네트워크인 `FeatureMap_convolution`, 두 개의 `RasidualBlockPSP`, 두 개의 `dilated 판 RasidualBlockPSP`로 구성."],"metadata":{"id":"KbFoIo9wBK9S"}},{"cell_type":"markdown","source":["네 번째 서브 네트워크인 `dilated 판 RasidualBlockPSP`의 출력텐서 1024 \\* 60 \\* 60 이 AuxLoss 모듈로 출력되는 점에 주의. \n","\n","AuxLoss 모듈에서 이 출력 텐서로 픽셀별 클래스를 분류하고 그 손실 값을 Feature 모듈의 전반부 네 개의 서브 네트워크를 학습하는데 사용. "],"metadata":{"id":"LLD6_3x0Bkj-"}},{"cell_type":"markdown","source":["### 서브 네트워크 FeatureMap_convolution"],"metadata":{"id":"KHnlMgENCIUW"}},{"cell_type":"markdown","source":["`FeatureMap_convolution`은 네 가지 요소로 구성됨\n","\n","- 합성곱 층\n","- 배치 정규화\n","- ReLu를 세트로 하는 `conv2dBatchNormReLu`가 세개, 최대 풀링층\n","\n","서브 네트워크 `FeatureMap_convolution`은 단순히 합성곱, 배치 정규화, 최대풀링으로 화상의 특징을 추출하는 역할을 함"],"metadata":{"id":"5V5hlwUSCMkF"}},{"cell_type":"markdown","source":["### FeatureMap_convolution 구현"],"metadata":{"id":"CMSpEgA8Cx11"}},{"cell_type":"markdown","source":["ReLu를 세트로 하는 `conv2dBatchNormReLu` 클래스 작성.\n","\n","ReLu 구현시 `nn.ReLu(inplace = True)`의 inplace는 메모리 입출력을 보존하면서 계산할 지 설정하는 파라미터."],"metadata":{"id":"3n4J_raXC3KN"}},{"cell_type":"code","source":["class conv2DBatchNormRelu(nn.Module):\n","  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n","    super(conv2DBatchNormRelu, self).__init__()\n","    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=bias)\n","    self.batchnorm = nn.BatchNorm2d(out_channels)\n","    self.relu = nn.ReLU(inplace=True)\n","    # inplase 설정으로 입력을 저장하지 않고 출력을 계산하여 메모리 절약\n","\n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.batchnorm(x)\n","    outputs = self.relu(x)\n","\n","    return outputs"],"metadata":{"id":"BQDPzUY2CvbK","executionInfo":{"status":"ok","timestamp":1664168902469,"user_tz":-540,"elapsed":11,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["`conv2DBatchNormRelu` 클래스를 사용하여 `FeatureMap_convolution` 클래스 작성."],"metadata":{"id":"6z-7HmmUDPTo"}},{"cell_type":"code","source":["class FeatureMap_convolution(nn.Module):\n","  def __init__(self):\n","    # 구성할 네트워크 준비\n","    super(FeatureMap_convolution, self).__init__()\n","\n","    # 합성곱 층 1\n","    in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n","    self.cbnr_1 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n","\n","    # 합성곱 층 2\n","    in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n","    self.cbnr_2 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n","\n","    # 합성곱 층 3\n","    in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n","    self.cbnr_3 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n","\n","    # MaxPooling\n","    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","  def forward(self, x):\n","    x = self.cbnr_1(x)\n","    x = self.cbnr_2(x)\n","    x = self.cbnr_3(x)\n","    outputs = self.maxpool(x)\n","    \n","    return outputs"],"metadata":{"id":"7RkfNvpkDbyQ","executionInfo":{"status":"ok","timestamp":1664168902469,"user_tz":-540,"elapsed":10,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## ResidualBlockPSP"],"metadata":{"id":"ti-dawo0DtZC"}},{"cell_type":"markdown","source":["Feature 모듈을 구성하는 두 개의 `ResidualBlockPSP`, 그리고 두 개의 dilated `ResidualBlockPSP`를 구현.\n","\n","`ResidualBlockPSP`는 `bottleNeckPSP` 클래스를 지나 `bottleNeckIdentifyPSP` 클래스를 여러번 반복하여 출력."],"metadata":{"id":"E_O4a0aqDxsN"}},{"cell_type":"markdown","source":["서브 네트워크 `ResidualBlockPSP` 을 구현."],"metadata":{"id":"mkY3rcB2Dxxl"}},{"cell_type":"code","source":["class ResidualBlockPSP(nn.Sequential):\n","  def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n","    super(ResidualBlockPSP, self).__init__()\n","\n","    # bottleNeckPSP 준비\n","    self.add_module(\n","      \"block1\",\n","      bottleNeckPSP(in_channels, mid_channels, out_channels, stride, dilation)\n","    )\n","\n","    # bottleNeckIdentifyPSP 반복 준비\n","    for i in range(n_blocks - 1):\n","      self.add_module(\n","        \"block\" + str(i+2),\n","        bottleNeckIdentifyPSP(out_channels, mid_channels, stride, dilation)\n","      )"],"metadata":{"id":"2ducFcTmEtaH","executionInfo":{"status":"ok","timestamp":1664168902469,"user_tz":-540,"elapsed":10,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## bottleNeckPSP 와 bottleNeckIdentifyPSP "],"metadata":{"id":"YFmHL1pPFGgQ"}},{"cell_type":"markdown","source":["ResidualBlockPSP 클래스에서 사용되는 bottleNeckPSP 와 bottleNeckIdentifyPSP 구현."],"metadata":{"id":"W2ey0nM4FLJB"}},{"cell_type":"markdown","source":["두 클래스는 특징적인 네트워크 구조를 가짐. 두 클래스는 입력이 두 갈래로 나누어 지는데, 그 중 하나는 스킵 결합이라고 함. `bottleNeckPSP` 와 `bottleNeckIdentifyPSP`의 차이는 이 스킵 결합에 합성곱층이 들어가는지 여부임.\n","\n","`bottleNeckPSP` 는 스킵결합에 합성곱층을 한 번 적용하지만,\n","`bottleNeckIdentifyPSP` 는 적용하지 않음"],"metadata":{"id":"LCUkmFogFZGW"}},{"cell_type":"markdown","source":["딥러닝에서, 심층 네트워크의 학습할 파라미터가 많으면 적을 때 보다 오차율이 적을 것이라고 생각 하지만 실제로는 그렇지 않은 경우가 있음. \n","\n","이것을 **열화 문제**라고 함.\n","\n","열화 문제를 피하기 위해 ResidualBlock의 입력 x를 그대로 출력하는 스킵 결합을 준비하는 것임."],"metadata":{"id":"F75daVBaF67e"}},{"cell_type":"markdown","source":["전체 네트워크의 오차를 줄일 수 있도록 아이디어를 고안해 낸 것이 스킵 결합을 가진 ResidualBlock임."],"metadata":{"id":"9sD6wBcJGWjx"}},{"cell_type":"markdown","source":["`ResidualBlockPSP` 에서는 합성곱 층에서 `dilation` 파라미터를 설정.\n","네 개의 `ResidualBlockPSP` 중에서 앞의 두개는 dilation을 1로, 뒤의 두 개는 2와 4로 설정 되있음.\n","\n","일반적인 합성곱층은 dilation 이 1임. 합성곱층에 1이 아닌 다른 dilation 값을 넣은 것을 `dilated Convolution`이라고 부름. dilation 값이 큰 `dilated Convolution` 일수록 더 거시적인 특징을 추출해 냄."],"metadata":{"id":"f7xw72gvGfuk"}},{"cell_type":"code","source":["class conv2DBatchNorm(nn.Module):\n","  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n","    super(conv2DBatchNorm, self).__init__()\n","    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=bias)\n","    self.batchnorm = nn.BatchNorm2d(out_channels)\n","\n","  def forward(self, x):\n","    x = self.conv(x)\n","    outputs = self.batchnorm(x)\n","\n","    return outputs\n","\n","\n","class bottleNeckPSP(nn.Module):\n","  def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n","      super(bottleNeckPSP, self).__init__()\n","\n","      self.cbr_1 = conv2DBatchNormRelu(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","      self.cbr_2 = conv2DBatchNormRelu(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n","      self.cb_3 = conv2DBatchNorm(mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","      # 스킵 결합\n","      self.cb_residual = conv2DBatchNorm(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n","\n","      self.relu = nn.ReLU(inplace=True)\n","\n","  def forward(self, x):\n","      conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n","      residual = self.cb_residual(x)\n","\n","      return self.relu(conv + residual)\n","\n","\n","class bottleNeckIdentifyPSP(nn.Module):\n","  def __init__(self, in_channels, mid_channels, stride, dilation):\n","      super(bottleNeckIdentifyPSP, self).__init__()\n","\n","      self.cbr_1 = conv2DBatchNormRelu(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","      self.cbr_2 = conv2DBatchNormRelu(mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n","      self.cb_3 = conv2DBatchNorm(mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","      self.relu = nn.ReLU(inplace=True)\n","\n","  def forward(self, x):\n","      conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n","      residual = x\n","      \n","      return self.relu(conv + residual)"],"metadata":{"id":"_oapLg30HLn3","executionInfo":{"status":"ok","timestamp":1664168902469,"user_tz":-540,"elapsed":10,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Pyramid Pooling 모듈 설명 및 구현"],"metadata":{"id":"358xU9fjHu9P"}},{"cell_type":"markdown","source":["### Pyramid Pooling 모듈의 서브 네트워크 구조"],"metadata":{"id":"wLdN8toFH1r_"}},{"cell_type":"markdown","source":["이곳에서는 Feature 모듈에서 출력된 텐서를 다섯개로 분기시킴. 가장 위의 분기는 Adaptive Average Pooling층으로 보내짐. 이곳에서는 화상을 지정된 크기로 Average Pooling을 함.\n","\n","다섯 분기중 네 개는 출력이 각각 6, 3, 2, 1인 Adaptive Average Pooling 층으로 보내짐. (6 \\* 6, 3 \\* 3, 2 \\* 2, 1 \\* 1)\n","\n","이렇게 점점 커지는 모양을 보고 피라미드와 비슷하여 붙여진 이름임."],"metadata":{"id":"cQmFLm_zH6zP"}},{"cell_type":"markdown","source":["Average Pooling 층을 통과한 텐서는 conv2DBatchNormReLu 클래스를 지나 업샘플층에 도달하고 작아진 특징맵의 크기를 60 \\* 60 으로 확대함."],"metadata":{"id":"G0pJQ5eSI30H"}},{"cell_type":"markdown","source":["다섯 분기중 마지막 한 개는 입력을 그대로 출력하여 위 네개의 분기와 결합시킴."],"metadata":{"id":"eI5fuht-JJF_"}},{"cell_type":"markdown","source":["### PyramidPooling 클래스 구현"],"metadata":{"id":"4z52Th5LJSFQ"}},{"cell_type":"markdown","source":["Pyramid Pooling 모듈은 `PyramidPooling` 클래스 만으로 구축함."],"metadata":{"id":"L85moK_FJYJI"}},{"cell_type":"code","source":["class PyramidPooling(nn.Module):\n","  def __init__(self, in_channels, pool_sizes, height, width):\n","    super(PyramidPooling, self).__init__()\n","\n","    # forward에서 사용하는 화상 크기\n","    self.height = height\n","    self.width = width\n","\n","    # 각 합성곱층의 출력 채널 수\n","    out_channels = int(in_channels / len(pool_sizes))\n","\n","    # 합성곱층 작성\n","    # 원래는 for 문으로 구성하는게 좋음.\n","    # pool_sizes: [6, 3, 2, 1]\n","    self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n","    self.cbr_1 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","    self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n","    self.cbr_2 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","    self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n","    self.cbr_3 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","    self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n","    self.cbr_4 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","  def forward(self, x):\n","\n","    out1 = self.cbr_1(self.avpool_1(x))\n","    out1 = F.interpolate(out1, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","    out2 = self.cbr_2(self.avpool_2(x))\n","    out2 = F.interpolate(out2, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","    out3 = self.cbr_3(self.avpool_3(x))\n","    out3 = F.interpolate(out3, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","    out4 = self.cbr_4(self.avpool_4(x))\n","    out4 = F.interpolate(out4, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","    # 최종 결합시킬 dim = 1 으로 채널 수 차원에서 결합\n","    output = torch.cat([x, out1, out2, out3, out4], dim=1)\n","\n","    return output"],"metadata":{"id":"WDzpUeHEJgvd","executionInfo":{"status":"ok","timestamp":1664168902469,"user_tz":-540,"elapsed":10,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Decoder, AuxLoss 모듈 설명 및 구현"],"metadata":{"id":"aOQEKfm0KG2T"}},{"cell_type":"markdown","source":["PSPNet의 Decoder 및 AuxLoss 모듈을 구성하는 서브 네트워크 구조 구현."],"metadata":{"id":"aRbR5sHBKKeo"}},{"cell_type":"markdown","source":["## Decoder 및 AuxLoss 모듈 구조"],"metadata":{"id":"0kXDTIZ5KTTy"}},{"cell_type":"markdown","source":["Decoder 및 AuxLoss 모듈은 이전에 출력된 텐서 정보를 Decode 합. 텐서 정보를 읽은 후 픽셀별로 물체 라벨을 클래스 분류로 추정하고 마지막으로 화상 크기를  원래의 475 * 475로 업샘플링 함."],"metadata":{"id":"ojM191O-Kbuf"}},{"cell_type":"markdown","source":["Decoder 와 AuxLoss 모듈 모두 동일한 네트워크 구성임. \n","\n","conv2DBatchNormReLu 클래스를 통과한 후 드롭아웃 층을 지나 합성곱층을 통과하여 텐서 크기가 21 \\* 60 \\* 60 이 됨. 마지막으로 업샘플층을 지나 원래의 475 사이즈의 화상으로 확대."],"metadata":{"id":"LdKVp2lQLKxt"}},{"cell_type":"markdown","source":["## Decoder 및 AuxLoss 모듈 구현"],"metadata":{"id":"FI3d0vgjLkxE"}},{"cell_type":"code","source":["class DecodePSPFeature(nn.Module):\n","  def __init__(self, height, width, n_classes):\n","    super(DecodePSPFeature, self).__init__()\n","\n","    # forward에 사용하는 화상 크기\n","    self.height = height\n","    self.width = width\n","\n","    self.cbr = conv2DBatchNormRelu(in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n","    self.dropout = nn.Dropout2d(p=0.1)\n","    self.classification = nn.Conv2d(in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","\n","  def forward(self, x):\n","    x = self.cbr(x)\n","    x = self.dropout(x)\n","    x = self.classification(x)\n","    output = F.interpolate(x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","    return output\n","\n","\n","class AuxiliaryPSPlayers(nn.Module):\n","  def __init__(self, in_channels, height, width, n_classes):\n","    super(AuxiliaryPSPlayers, self).__init__()\n","\n","    # forward에 사용하는 화상 크기\n","    self.height = height\n","    self.width = width\n","\n","    self.cbr = conv2DBatchNormRelu(in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n","    self.dropout = nn.Dropout2d(p=0.1)\n","    self.classification = nn.Conv2d(in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","\n","  def forward(self, x):\n","    x = self.cbr(x)\n","    x = self.dropout(x)\n","    x = self.classification(x)\n","    output = F.interpolate(x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","    return output"],"metadata":{"id":"zxbAiA3tLqot","executionInfo":{"status":"ok","timestamp":1664168902470,"user_tz":-540,"elapsed":10,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["마지막 클래스 분류시 전결합층을 사용하지 않고 클래스 수와 동일하게 21을 출력 채널로 하는 커널크기 1의 합성곱층을 사용하는 것이 특징임."],"metadata":{"id":"WaMBaYSEMH8V"}},{"cell_type":"markdown","source":["마지막으로 네트워크 모델인 PSPNet 클래스의 인스턴스를 작성하고 오류 없이 계산되는지 확인."],"metadata":{"id":"SNf9veJ7MUxW"}},{"cell_type":"code","source":["# 모델 정의\n","net = PSPNet(n_classes=21)\n","net"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Yzb5DMhMe_s","executionInfo":{"status":"ok","timestamp":1664168915863,"user_tz":-540,"elapsed":934,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"8b577e1c-c4b4-4e90-ccce-c432b2551d08"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PSPNet(\n","  (feature_conv): FeatureMap_convolution(\n","    (cbnr_1): conv2DBatchNormRelu(\n","      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (cbnr_2): conv2DBatchNormRelu(\n","      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (cbnr_3): conv2DBatchNormRelu(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (feature_res_1): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (feature_res_2): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block4): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (feature_dilated_res_1): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block4): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block5): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block6): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (feature_dilated_res_2): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (pyramid_pooling): PyramidPooling(\n","    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n","    (cbr_1): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n","    (cbr_2): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n","    (cbr_3): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n","    (cbr_4): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (decode_feature): DecodePSPFeature(\n","    (cbr): conv2DBatchNormRelu(\n","      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (aux): AuxiliaryPSPlayers(\n","    (cbr): conv2DBatchNormRelu(\n","      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# 더미 데이터\n","batch_size = 2\n","dummy_img = torch.rand(batch_size, 3, 475, 475)\n","\n","# 계산\n","outputs = net(dummy_img)\n","print(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3imUd4jxMiWd","executionInfo":{"status":"ok","timestamp":1664168929593,"user_tz":-540,"elapsed":13384,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"fe9296cb-dc2c-4faa-ace9-42bfc8fdecb5"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[[[ 6.2830e-01,  6.0226e-01,  5.7622e-01,  ...,  5.0809e-01,\n","            4.7802e-01,  4.4794e-01],\n","          [ 6.4608e-01,  6.1405e-01,  5.8203e-01,  ...,  5.1379e-01,\n","            4.8246e-01,  4.5114e-01],\n","          [ 6.6386e-01,  6.2585e-01,  5.8784e-01,  ...,  5.1948e-01,\n","            4.8690e-01,  4.5433e-01],\n","          ...,\n","          [ 4.3632e-01,  4.0551e-01,  3.7469e-01,  ...,  6.0906e-01,\n","            6.1720e-01,  6.2535e-01],\n","          [ 4.7366e-01,  4.3830e-01,  4.0295e-01,  ...,  6.1364e-01,\n","            6.1677e-01,  6.1989e-01],\n","          [ 5.1099e-01,  4.7110e-01,  4.3121e-01,  ...,  6.1822e-01,\n","            6.1633e-01,  6.1444e-01]],\n","\n","         [[ 4.5468e-01,  4.4113e-01,  4.2758e-01,  ...,  6.0992e-01,\n","            6.6600e-01,  7.2208e-01],\n","          [ 4.2980e-01,  4.1977e-01,  4.0975e-01,  ...,  6.1643e-01,\n","            6.6121e-01,  7.0599e-01],\n","          [ 4.0491e-01,  3.9841e-01,  3.9191e-01,  ...,  6.2294e-01,\n","            6.5642e-01,  6.8991e-01],\n","          ...,\n","          [ 3.7552e-01,  3.8027e-01,  3.8503e-01,  ...,  1.6713e-01,\n","            1.7194e-01,  1.7675e-01],\n","          [ 3.0478e-01,  3.1865e-01,  3.3252e-01,  ...,  1.5467e-01,\n","            1.6018e-01,  1.6568e-01],\n","          [ 2.3404e-01,  2.5703e-01,  2.8001e-01,  ...,  1.4222e-01,\n","            1.4842e-01,  1.5462e-01]],\n","\n","         [[-5.7699e-01, -5.6289e-01, -5.4880e-01,  ..., -2.3330e-01,\n","           -2.6358e-01, -2.9386e-01],\n","          [-5.9610e-01, -5.9406e-01, -5.9202e-01,  ..., -2.9477e-01,\n","           -3.2121e-01, -3.4764e-01],\n","          [-6.1520e-01, -6.2522e-01, -6.3523e-01,  ..., -3.5625e-01,\n","           -3.7884e-01, -4.0143e-01],\n","          ...,\n","          [-3.3995e-01, -3.9398e-01, -4.4800e-01,  ..., -3.0030e-01,\n","           -2.3738e-01, -1.7446e-01],\n","          [-3.1856e-01, -3.7968e-01, -4.4080e-01,  ..., -2.7987e-01,\n","           -2.1198e-01, -1.4408e-01],\n","          [-2.9716e-01, -3.6538e-01, -4.3359e-01,  ..., -2.5945e-01,\n","           -1.8657e-01, -1.1369e-01]],\n","\n","         ...,\n","\n","         [[-5.9695e-02, -5.8310e-02, -5.6926e-02,  ...,  1.5030e-01,\n","            1.4001e-01,  1.2972e-01],\n","          [-1.6866e-02, -2.2487e-02, -2.8109e-02,  ...,  1.2366e-01,\n","            1.1230e-01,  1.0094e-01],\n","          [ 2.5963e-02,  1.3335e-02,  7.0770e-04,  ...,  9.7009e-02,\n","            8.4586e-02,  7.2163e-02],\n","          ...,\n","          [ 4.8744e-01,  5.1840e-01,  5.4935e-01,  ..., -3.1987e-01,\n","           -3.9108e-01, -4.6229e-01],\n","          [ 4.9316e-01,  5.3066e-01,  5.6817e-01,  ..., -3.3131e-01,\n","           -3.9944e-01, -4.6758e-01],\n","          [ 4.9887e-01,  5.4293e-01,  5.8699e-01,  ..., -3.4275e-01,\n","           -4.0781e-01, -4.7286e-01]],\n","\n","         [[-3.5421e-01, -3.5068e-01, -3.4715e-01,  ..., -3.8535e-01,\n","           -3.8432e-01, -3.8329e-01],\n","          [-3.6928e-01, -3.6708e-01, -3.6488e-01,  ..., -3.7094e-01,\n","           -3.5713e-01, -3.4332e-01],\n","          [-3.8435e-01, -3.8348e-01, -3.8262e-01,  ..., -3.5653e-01,\n","           -3.2994e-01, -3.0335e-01],\n","          ...,\n","          [-3.8702e-01, -3.4227e-01, -2.9751e-01,  ..., -2.7180e-01,\n","           -3.1830e-01, -3.6479e-01],\n","          [-4.6525e-01, -4.0639e-01, -3.4753e-01,  ..., -3.1550e-01,\n","           -3.6937e-01, -4.2324e-01],\n","          [-5.4348e-01, -4.7051e-01, -3.9754e-01,  ..., -3.5919e-01,\n","           -4.2044e-01, -4.8170e-01]],\n","\n","         [[ 2.3898e-01,  2.1793e-01,  1.9689e-01,  ...,  1.5991e-01,\n","            1.7115e-01,  1.8240e-01],\n","          [ 1.9720e-01,  1.8913e-01,  1.8106e-01,  ...,  1.5717e-01,\n","            1.7520e-01,  1.9324e-01],\n","          [ 1.5543e-01,  1.6033e-01,  1.6524e-01,  ...,  1.5443e-01,\n","            1.7925e-01,  2.0408e-01],\n","          ...,\n","          [ 2.3939e-01,  2.1262e-01,  1.8585e-01,  ..., -2.6491e-01,\n","           -3.2381e-01, -3.8270e-01],\n","          [ 2.1869e-01,  1.9779e-01,  1.7690e-01,  ..., -2.3139e-01,\n","           -2.8929e-01, -3.4719e-01],\n","          [ 1.9798e-01,  1.8296e-01,  1.6795e-01,  ..., -1.9787e-01,\n","           -2.5477e-01, -3.1167e-01]]],\n","\n","\n","        [[[ 5.8376e-01,  5.3705e-01,  4.9034e-01,  ...,  4.6526e-01,\n","            4.9608e-01,  5.2691e-01],\n","          [ 5.9414e-01,  5.4793e-01,  5.0171e-01,  ...,  4.5944e-01,\n","            4.8859e-01,  5.1774e-01],\n","          [ 6.0453e-01,  5.5880e-01,  5.1307e-01,  ...,  4.5362e-01,\n","            4.8110e-01,  5.0858e-01],\n","          ...,\n","          [ 8.2388e-01,  7.7403e-01,  7.2417e-01,  ...,  1.6030e-01,\n","            9.5110e-02,  2.9922e-02],\n","          [ 8.4756e-01,  7.9685e-01,  7.4614e-01,  ...,  1.2343e-01,\n","            5.1487e-02, -2.0452e-02],\n","          [ 8.7123e-01,  8.1967e-01,  7.6811e-01,  ...,  8.6554e-02,\n","            7.8642e-03, -7.0825e-02]],\n","\n","         [[ 4.2809e-01,  4.8220e-01,  5.3632e-01,  ...,  4.8689e-01,\n","            4.9529e-01,  5.0369e-01],\n","          [ 3.9331e-01,  4.3713e-01,  4.8095e-01,  ...,  5.0356e-01,\n","            5.1939e-01,  5.3522e-01],\n","          [ 3.5852e-01,  3.9206e-01,  4.2559e-01,  ...,  5.2024e-01,\n","            5.4350e-01,  5.6675e-01],\n","          ...,\n","          [ 3.6554e-01,  3.2109e-01,  2.7664e-01,  ...,  4.0619e-02,\n","            6.9538e-02,  9.8456e-02],\n","          [ 3.6614e-01,  3.1378e-01,  2.6142e-01,  ...,  2.0007e-02,\n","            5.9367e-02,  9.8728e-02],\n","          [ 3.6674e-01,  3.0647e-01,  2.4619e-01,  ..., -6.0481e-04,\n","            4.9197e-02,  9.8999e-02]],\n","\n","         [[-9.6324e-01, -9.1905e-01, -8.7487e-01,  ..., -6.8408e-01,\n","           -6.3059e-01, -5.7710e-01],\n","          [-9.1956e-01, -8.7651e-01, -8.3346e-01,  ..., -6.9614e-01,\n","           -6.5006e-01, -6.0399e-01],\n","          [-8.7588e-01, -8.3397e-01, -7.9205e-01,  ..., -7.0820e-01,\n","           -6.6953e-01, -6.3087e-01],\n","          ...,\n","          [-4.1498e-01, -4.2045e-01, -4.2592e-01,  ..., -4.6885e-01,\n","           -4.1743e-01, -3.6600e-01],\n","          [-4.1493e-01, -4.0645e-01, -3.9797e-01,  ..., -4.6767e-01,\n","           -4.1005e-01, -3.5243e-01],\n","          [-4.1487e-01, -3.9245e-01, -3.7002e-01,  ..., -4.6649e-01,\n","           -4.0268e-01, -3.3886e-01]],\n","\n","         ...,\n","\n","         [[-3.1674e-01, -2.9322e-01, -2.6970e-01,  ..., -5.5079e-02,\n","           -3.9351e-02, -2.3623e-02],\n","          [-2.5789e-01, -2.4053e-01, -2.2317e-01,  ..., -8.9289e-02,\n","           -7.9723e-02, -7.0156e-02],\n","          [-1.9904e-01, -1.8784e-01, -1.7665e-01,  ..., -1.2350e-01,\n","           -1.2009e-01, -1.1669e-01],\n","          ...,\n","          [ 4.4596e-01,  4.3237e-01,  4.1878e-01,  ...,  1.2041e-01,\n","            5.5663e-02, -9.0797e-03],\n","          [ 4.9110e-01,  4.7822e-01,  4.6534e-01,  ...,  1.6688e-01,\n","            1.0775e-01,  4.8622e-02],\n","          [ 5.3624e-01,  5.2407e-01,  5.1190e-01,  ...,  2.1336e-01,\n","            1.5984e-01,  1.0632e-01]],\n","\n","         [[-2.0905e-01, -1.6932e-01, -1.2958e-01,  ..., -3.0283e-01,\n","           -2.9941e-01, -2.9600e-01],\n","          [-2.0368e-01, -1.7013e-01, -1.3657e-01,  ..., -3.1160e-01,\n","           -3.0548e-01, -2.9935e-01],\n","          [-1.9831e-01, -1.7093e-01, -1.4355e-01,  ..., -3.2038e-01,\n","           -3.1154e-01, -3.0270e-01],\n","          ...,\n","          [-1.0326e-01, -1.3631e-01, -1.6935e-01,  ...,  1.8664e-01,\n","            2.1521e-01,  2.4378e-01],\n","          [-1.3169e-01, -1.7006e-01, -2.0844e-01,  ...,  1.3135e-01,\n","            1.5958e-01,  1.8781e-01],\n","          [-1.6012e-01, -2.0382e-01, -2.4753e-01,  ...,  7.6071e-02,\n","            1.0396e-01,  1.3184e-01]],\n","\n","         [[-3.6083e-02, -2.7927e-02, -1.9771e-02,  ..., -2.4239e-01,\n","           -3.2032e-01, -3.9824e-01],\n","          [-3.5129e-03,  9.8282e-04,  5.4785e-03,  ..., -1.8715e-01,\n","           -2.5000e-01, -3.1284e-01],\n","          [ 2.9057e-02,  2.9893e-02,  3.0728e-02,  ..., -1.3190e-01,\n","           -1.7967e-01, -2.2745e-01],\n","          ...,\n","          [ 3.1772e-01,  2.9374e-01,  2.6975e-01,  ..., -1.1838e-01,\n","           -1.8802e-01, -2.5765e-01],\n","          [ 3.3350e-01,  3.0540e-01,  2.7731e-01,  ..., -1.3822e-01,\n","           -2.1163e-01, -2.8505e-01],\n","          [ 3.4927e-01,  3.1706e-01,  2.8486e-01,  ..., -1.5805e-01,\n","           -2.3525e-01, -3.1245e-01]]]], grad_fn=<UpsampleBilinear2DBackward1>), tensor([[[[ 0.0729,  0.0562,  0.0396,  ..., -0.1493, -0.2149, -0.2806],\n","          [ 0.1351,  0.1099,  0.0847,  ..., -0.1562, -0.2168, -0.2774],\n","          [ 0.1974,  0.1636,  0.1298,  ..., -0.1632, -0.2187, -0.2742],\n","          ...,\n","          [ 0.1157,  0.1379,  0.1602,  ..., -0.0384, -0.0774, -0.1164],\n","          [ 0.1440,  0.1671,  0.1902,  ..., -0.0213, -0.0612, -0.1011],\n","          [ 0.1722,  0.1962,  0.2202,  ..., -0.0043, -0.0451, -0.0859]],\n","\n","         [[ 0.1333,  0.0862,  0.0391,  ..., -0.1609, -0.1542, -0.1476],\n","          [ 0.1037,  0.0595,  0.0154,  ..., -0.1379, -0.1379, -0.1380],\n","          [ 0.0741,  0.0328, -0.0084,  ..., -0.1148, -0.1216, -0.1284],\n","          ...,\n","          [-0.1562, -0.1584, -0.1606,  ...,  0.1293,  0.1202,  0.1111],\n","          [-0.1863, -0.1838, -0.1812,  ...,  0.1005,  0.0883,  0.0761],\n","          [-0.2165, -0.2092, -0.2019,  ...,  0.0716,  0.0564,  0.0412]],\n","\n","         [[-0.7981, -0.7429, -0.6877,  ..., -0.7655, -0.8104, -0.8553],\n","          [-0.7908, -0.7395, -0.6883,  ..., -0.7607, -0.8114, -0.8622],\n","          [-0.7835, -0.7362, -0.6889,  ..., -0.7559, -0.8125, -0.8690],\n","          ...,\n","          [-0.4317, -0.4026, -0.3735,  ..., -0.4295, -0.4543, -0.4791],\n","          [-0.4587, -0.4245, -0.3903,  ..., -0.4125, -0.4271, -0.4417],\n","          [-0.4857, -0.4464, -0.4070,  ..., -0.3955, -0.3999, -0.4043]],\n","\n","         ...,\n","\n","         [[-0.1733, -0.1826, -0.1918,  ..., -0.3610, -0.3658, -0.3706],\n","          [-0.1848, -0.1872, -0.1896,  ..., -0.3263, -0.3323, -0.3383],\n","          [-0.1962, -0.1918, -0.1875,  ..., -0.2916, -0.2988, -0.3060],\n","          ...,\n","          [-0.1383, -0.1212, -0.1040,  ...,  0.0156,  0.0660,  0.1164],\n","          [-0.1220, -0.1039, -0.0857,  ...,  0.0040,  0.0434,  0.0827],\n","          [-0.1057, -0.0866, -0.0674,  ..., -0.0075,  0.0207,  0.0490]],\n","\n","         [[ 0.3412,  0.3158,  0.2904,  ...,  0.2632,  0.2421,  0.2210],\n","          [ 0.3990,  0.3730,  0.3471,  ...,  0.2593,  0.2387,  0.2181],\n","          [ 0.4568,  0.4302,  0.4037,  ...,  0.2553,  0.2353,  0.2153],\n","          ...,\n","          [ 0.4191,  0.4295,  0.4398,  ...,  0.3811,  0.4165,  0.4519],\n","          [ 0.4408,  0.4561,  0.4714,  ...,  0.3767,  0.4123,  0.4478],\n","          [ 0.4625,  0.4827,  0.5029,  ...,  0.3723,  0.4081,  0.4438]],\n","\n","         [[ 0.2349,  0.2541,  0.2733,  ..., -0.0999, -0.1331, -0.1662],\n","          [ 0.2070,  0.2276,  0.2482,  ..., -0.0856, -0.1111, -0.1365],\n","          [ 0.1791,  0.2011,  0.2232,  ..., -0.0713, -0.0891, -0.1069],\n","          ...,\n","          [-0.1684, -0.1317, -0.0950,  ...,  0.1845,  0.1957,  0.2069],\n","          [-0.1897, -0.1539, -0.1181,  ...,  0.1252,  0.1358,  0.1465],\n","          [-0.2111, -0.1762, -0.1412,  ...,  0.0658,  0.0760,  0.0861]]],\n","\n","\n","        [[[ 0.4689,  0.4798,  0.4907,  ...,  0.0838,  0.0602,  0.0366],\n","          [ 0.4111,  0.4261,  0.4411,  ...,  0.0471,  0.0264,  0.0057],\n","          [ 0.3533,  0.3724,  0.3914,  ...,  0.0104, -0.0074, -0.0252],\n","          ...,\n","          [ 0.2213,  0.2222,  0.2230,  ...,  0.0431,  0.0268,  0.0105],\n","          [ 0.2410,  0.2464,  0.2517,  ...,  0.0482,  0.0312,  0.0142],\n","          [ 0.2608,  0.2706,  0.2805,  ...,  0.0532,  0.0355,  0.0178]],\n","\n","         [[-0.5371, -0.5282, -0.5192,  ..., -0.4582, -0.4610, -0.4637],\n","          [-0.5405, -0.5316, -0.5227,  ..., -0.4511, -0.4543, -0.4576],\n","          [-0.5439, -0.5350, -0.5262,  ..., -0.4440, -0.4477, -0.4514],\n","          ...,\n","          [-0.6223, -0.5887, -0.5551,  ..., -0.2155, -0.2377, -0.2599],\n","          [-0.7041, -0.6651, -0.6261,  ..., -0.2172, -0.2344, -0.2516],\n","          [-0.7858, -0.7415, -0.6971,  ..., -0.2189, -0.2311, -0.2433]],\n","\n","         [[-0.4165, -0.4458, -0.4751,  ..., -0.5536, -0.5721, -0.5906],\n","          [-0.4355, -0.4605, -0.4855,  ..., -0.5513, -0.5725, -0.5937],\n","          [-0.4545, -0.4752, -0.4960,  ..., -0.5489, -0.5729, -0.5968],\n","          ...,\n","          [-1.0025, -0.9799, -0.9572,  ..., -0.3204, -0.3111, -0.3018],\n","          [-1.0171, -0.9898, -0.9625,  ..., -0.2876, -0.2778, -0.2679],\n","          [-1.0318, -0.9998, -0.9679,  ..., -0.2548, -0.2444, -0.2341]],\n","\n","         ...,\n","\n","         [[-0.2323, -0.2378, -0.2432,  ..., -0.3294, -0.3311, -0.3329],\n","          [-0.2590, -0.2645, -0.2701,  ..., -0.3302, -0.3362, -0.3421],\n","          [-0.2856, -0.2913, -0.2969,  ..., -0.3310, -0.3412, -0.3514],\n","          ...,\n","          [-0.2935, -0.2462, -0.1988,  ..., -0.0082, -0.0035,  0.0013],\n","          [-0.3180, -0.2613, -0.2047,  ...,  0.0319,  0.0377,  0.0434],\n","          [-0.3424, -0.2765, -0.2105,  ...,  0.0721,  0.0788,  0.0855]],\n","\n","         [[ 0.5262,  0.4573,  0.3884,  ...,  0.0373,  0.0353,  0.0333],\n","          [ 0.5678,  0.5014,  0.4349,  ...,  0.0446,  0.0468,  0.0491],\n","          [ 0.6093,  0.5454,  0.4815,  ...,  0.0520,  0.0584,  0.0649],\n","          ...,\n","          [ 0.4097,  0.4382,  0.4668,  ...,  0.4864,  0.5078,  0.5291],\n","          [ 0.4210,  0.4551,  0.4891,  ...,  0.5313,  0.5521,  0.5728],\n","          [ 0.4323,  0.4719,  0.5115,  ...,  0.5763,  0.5964,  0.6165]],\n","\n","         [[ 0.2203,  0.2220,  0.2236,  ..., -0.4647, -0.4387, -0.4127],\n","          [ 0.2038,  0.2093,  0.2149,  ..., -0.3718, -0.3503, -0.3288],\n","          [ 0.1872,  0.1967,  0.2061,  ..., -0.2789, -0.2619, -0.2449],\n","          ...,\n","          [-0.2281, -0.2249, -0.2217,  ...,  0.0956,  0.1034,  0.1113],\n","          [-0.2562, -0.2536, -0.2509,  ...,  0.0661,  0.0739,  0.0818],\n","          [-0.2842, -0.2822, -0.2801,  ...,  0.0366,  0.0444,  0.0522]]]],\n","       grad_fn=<UpsampleBilinear2DBackward1>))\n"]}]}]}