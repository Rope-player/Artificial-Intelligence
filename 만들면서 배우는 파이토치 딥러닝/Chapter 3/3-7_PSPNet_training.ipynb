{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNYdo6fiUVZjo6uw7jWU3Q3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q6HTGX6Xuq5g","executionInfo":{"status":"ok","timestamp":1664246827350,"user_tz":-540,"elapsed":3105,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"45de70fa-e000-4b3c-cb93-ad8aa04c3386"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pytorch_advanced'...\n","remote: Enumerating objects: 548, done.\u001b[K\n","remote: Counting objects: 100% (174/174), done.\u001b[K\n","remote: Compressing objects: 100% (173/173), done.\u001b[K\n","remote: Total 548 (delta 5), reused 162 (delta 0), pack-reused 374\u001b[K\n","Receiving objects: 100% (548/548), 50.13 MiB | 35.65 MiB/s, done.\n","Resolving deltas: 100% (43/43), done.\n"]}],"source":["!git clone https://github.com/Rope-player/pytorch_advanced.git"]},{"cell_type":"code","source":["%cd \"pytorch_advanced\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_airOnoXvL2Y","executionInfo":{"status":"ok","timestamp":1664246827350,"user_tz":-540,"elapsed":5,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"6ffe186f-09fb-4569-92bb-52057a0354b1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/pytorch_advanced\n"]}]},{"cell_type":"code","source":["%cd \"3_semantic_segmentation\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WKHFp6W1vL4_","executionInfo":{"status":"ok","timestamp":1664246827350,"user_tz":-540,"elapsed":4,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"23e18800-cd0f-4521-b61c-bbfb11dfa228"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/pytorch_advanced/3_semantic_segmentation\n"]}]},{"cell_type":"code","source":["import os\n","import urllib.request\n","import zipfile\n","import tarfile"],"metadata":{"id":"8pDpeJQhvNKo","executionInfo":{"status":"ok","timestamp":1664246827351,"user_tz":-540,"elapsed":5,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_dir = \"./data/\"\n","if not os.path.exists(data_dir):\n","  os.mkdir(data_dir)"],"metadata":{"id":"Gmy09ic6vNMn","executionInfo":{"status":"ok","timestamp":1664246827351,"user_tz":-540,"elapsed":4,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["weights_dir = \"./weights/\"\n","if not os.path.exists(weights_dir):\n","  os.mkdir(weights_dir)"],"metadata":{"id":"nmRBt4FkvL7o","executionInfo":{"status":"ok","timestamp":1664246827351,"user_tz":-540,"elapsed":4,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n","target_path = os.path.join(data_dir, \"VOCtrainval_11-May-2012.tar\") \n","\n","if not os.path.exists(target_path):\n","  urllib.request.urlretrieve(url, target_path)\n","    \n","  tar = tarfile.TarFile(target_path)  \n","  tar.extractall(data_dir)  \n","  tar.close()"],"metadata":{"id":"-JssXjjJvL-X","executionInfo":{"status":"ok","timestamp":1664246912178,"user_tz":-540,"elapsed":84831,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!gdown https://drive.google.com/uc?id=12eN6SpnawYuQmD1k9VgVW3QSgPR6hICc&export=download   # 학습 된 파라미터 다운로드"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MgjqXOksv-Js","executionInfo":{"status":"ok","timestamp":1664246916876,"user_tz":-540,"elapsed":4706,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"73e204ed-763f-44f0-b34b-0ba0fb046748"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=12eN6SpnawYuQmD1k9VgVW3QSgPR6hICc\n","To: /content/pytorch_advanced/3_semantic_segmentation/pspnet50_ADE20K.pth\n","100% 197M/197M [00:03<00:00, 60.2MB/s]\n"]}]},{"cell_type":"code","source":["!mv /content/pytorch_advanced/3_semantic_segmentation/pspnet50_ADE20K.pth /content/pytorch_advanced/3_semantic_segmentation/weights"],"metadata":{"id":"_gOFumxQxlo8","executionInfo":{"status":"ok","timestamp":1664246978923,"user_tz":-540,"elapsed":281,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import random\n","import math\n","import time\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","import torch.optim as optim"],"metadata":{"id":"4GW8J5CSvMB3","executionInfo":{"status":"ok","timestamp":1664247083472,"user_tz":-540,"elapsed":3225,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)"],"metadata":{"id":"EW4eN8WE2vUD","executionInfo":{"status":"ok","timestamp":1664247085716,"user_tz":-540,"elapsed":254,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# 파인튜닝을 활용한 학습 및 검증 실시:"],"metadata":{"id":"oose_M8Hu0vq"}},{"cell_type":"markdown","source":["## 학습 및 검증 구현"],"metadata":{"id":"Gsd7zJJZu6GD"}},{"cell_type":"markdown","source":["데이터 로더 작성. 미니 배치 크기는 1gpu 메모리에 담기는 여덟개로 설정."],"metadata":{"id":"2l7ufcmKvTvU"}},{"cell_type":"code","source":["from utils.dataloader import make_datapath_list, DataTransform, VOCDataset\n","\n","# 파일 경로 리스트\n","rootpath = \"./data/VOCdevkit/VOC2012/\"\n","train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath=rootpath)\n","\n","# 데이터셋 작성\n","# (RGB)의 평균값과 표준편차\n","color_mean = (0.485, 0.456, 0.406)\n","color_std = (0.229, 0.224, 0.225)\n","\n","train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(input_size=475, color_mean=color_mean, color_std=color_std))\n","val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(input_size=475, color_mean=color_mean, color_std=color_std))\n","\n","# 데이터로더 작성\n","batch_size = 8\n","\n","train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# 사전형 변수로 함수 정리\n","dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"],"metadata":{"id":"W4HzCQrg2q5o","executionInfo":{"status":"ok","timestamp":1664247161716,"user_tz":-540,"elapsed":659,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["네트워크 모델을 만들기 위해 먼저 ADE20K 네트워크 모델 준비.\n","\n","최종 출력층을 Pascal VOC의 21 클래스로 하기 위하여 Decoder와 AuxLoss 모듈의 분류용 합성곱층을 바꿈 "],"metadata":{"id":"1MQ1dkJL3GkB"}},{"cell_type":"markdown","source":["교체한 합성곱 층은 **Xavier의 초기값**으로 초기화.\n","\n","Xavier의 초기값은 각 합성곱 층에서 입력 채널 수가 `input_n`일때 합성곱층의 결합 파라미터 초기값으로 '`1/sqrt(input_n)`을 표준편차로 한 가우스'에 따라 난수를 사용하는 기법.\n","\n","이번엔 분류용 유닛의 마지막층이자 활성화 함수인 **시그모이드** 함수 사용. 시그모이드 함수일 경우 Xavier 초기값으로 초기화 함."],"metadata":{"id":"4rmQ5oyS3te2"}},{"cell_type":"code","source":["from utils.pspnet import PSPNet\n","\n","# 파인튜닝으로 PSPNet 작성\n","# ADE20K 데이터셋의 학습된 모델을 사용하여 ADE20 클래스 수는 150\n","net = PSPNet(n_classes=150)\n","\n","\n","# ADE20K 학습된 파라미터 읽기\n","state_dict = torch.load(\"./weights/pspnet50_ADE20K.pth\")\n","net.load_state_dict(state_dict)\n","\n","\n","# 분류용 합성곱 층을 출력수 21로 변경\n","n_classes = 21\n","net.decode_feature.classification = nn.Conv2d(in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","net.aux.classification = nn.Conv2d(in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","\n","\n","# 교체한 합성곱 층을 초기화 . 활성화 함수는 시그모이드 함수이므로 Xavier 사용\n","def weights_init(m):\n","  if isinstance(m, nn.Conv2d):\n","    nn.init.xavier_normal_(m.weight.data)\n","    if m.bias is not None:  # 바이어스항이 있는 경우\n","      nn.init.constant_(m.bias, 0.0)\n","\n","\n","net.decode_feature.classification.apply(weights_init)\n","net.aux.classification.apply(weights_init)\n","\n","\n","print('네트워크 설정완료: 학습된 가중치를 로드했습니다.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APHjGeTU4XNd","executionInfo":{"status":"ok","timestamp":1664247643563,"user_tz":-540,"elapsed":1852,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"d76426c4-7c14-4234-ce9d-3afc5957db87"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["네트워크 설정완료: 학습된 가중치를 로드했습니다.\n"]}]},{"cell_type":"markdown","source":["다 클래스 분류의 손실함수 크로스 엔트로피 오차 함수로 손실함수를 구현. 메인 손실과 AuxLoss 합을 총 손실로 합니다. AuxLoss는 계수 0.4를 곱하여 가중치를 메인 손실 보다 작게 함."],"metadata":{"id":"muaQZeQr4_ME"}},{"cell_type":"code","source":["class PSPLoss(nn.Module):\n","    # PSPNet 손실 함수 클래스\n","\n","  def __init__(self, aux_weight=0.4):\n","    super(PSPLoss, self).__init__()\n","    self.aux_weight = aux_weight  # aux_loss 가중치\n","\n","  def forward(self, outputs, targets):\n","    # 손실함수 계산\n","\n","    # Parameters\n","    #   outputs : PSPNet 출력(tuple) - (output=torch.Size([num_batch, 21, 475, 475]), output_aux=torch.Size([num_batch, 21, 475, 475]))\n","    #   targets : [num_batch, 475, 475] - 정답 어노테이션 정보\n","    # Returns\n","    #   loss    : 텐서 - 손실 값\n","\n","    loss = F.cross_entropy(outputs[0], targets, reduction='mean')\n","    loss_aux = F.cross_entropy(outputs[1], targets, reduction='mean')\n","\n","    return loss+self.aux_weight*loss_aux\n","\n","criterion = PSPLoss(aux_weight=0.4)"],"metadata":{"id":"t_2H9DLP5RC8","executionInfo":{"status":"ok","timestamp":1664247905925,"user_tz":-540,"elapsed":287,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## 스케쥴러로 에폭별 학습 비율 변경"],"metadata":{"id":"gbb9sZVU58jI"}},{"cell_type":"markdown","source":["에폭에 따라 학습률을 변화시키는 스케줄러 활용. 코드 `scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)`에 정의 됨.\n","\n","`lambda_epoch` 함수에 따라 옵티마이저 인스턴스의 학습률을 변화시킴. `lambda_epoch` 함수는 최대 에폭 수를 30으로 하고 에폭을 거칠 때마다 학습률이 서서히 작아지도록 함. `return`하는 값을 옵티마이저 학습률에 곱함.\n","\n","스케쥴러의 학습률을 변화시키려면 네트워크 학습시 `scheduler.step()`을 실행하면 됨."],"metadata":{"id":"xqe97wVS6B7d"}},{"cell_type":"code","source":["optimizer = optim.SGD([\n","  {'params': net.feature_conv.parameters(), 'lr': 1e-3},\n","  {'params': net.feature_res_1.parameters(), 'lr': 1e-3},\n","  {'params': net.feature_res_2.parameters(), 'lr': 1e-3},\n","  {'params': net.feature_dilated_res_1.parameters(), 'lr': 1e-3},\n","  {'params': net.feature_dilated_res_2.parameters(), 'lr': 1e-3},\n","  {'params': net.pyramid_pooling.parameters(), 'lr': 1e-3},\n","  {'params': net.decode_feature.parameters(), 'lr': 1e-2},\n","  {'params': net.aux.parameters(), 'lr': 1e-2},\n","], momentum=0.9, weight_decay=0.0001)\n","\n","\n","# 스케줄러 설정\n","def lambda_epoch(epoch):\n","  max_epoch = 30\n","  return math.pow((1-epoch/max_epoch), 0.9)\n","\n","\n","scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)"],"metadata":{"id":"jMThdE8_6LKM","executionInfo":{"status":"ok","timestamp":1664249037962,"user_tz":-540,"elapsed":262,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["검증용 함수인 train_model 작성.\n","\n","2장의 train_model과의 차이점\n","\n","*   스케줄러가 존재함\n","*   멀티플 미니 배치 사용\n","\n","batch_multi"],"metadata":{"id":"k5MXk01a7Jab"}},{"cell_type":"code","source":["def train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs):\n","\n","  # GPU를 사용가능한지 확인.\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(\"使用デバイス：\", device)\n","\n","  # 네트워크를 GPU로\n","  net.to(device)\n","\n","  # 네트워크가 어느 정도 고정되면 고속화\n","  torch.backends.cudnn.benchmark = True\n","\n","  # 화상 매수\n","  num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n","  num_val_imgs = len(dataloaders_dict[\"val\"].dataset)\n","  batch_size = dataloaders_dict[\"train\"].batch_size\n","\n","  # 반복자의 카운터 설정\n","  iteration = 1\n","  logs = []\n","\n","  # 멀티플 미니 배치\n","  batch_multiplier = 3\n","\n","  # 에폭 루프\n","  for epoch in range(num_epochs):\n","\n","    # 시작 시간 저장\n","    t_epoch_start = time.time()\n","    t_iter_start = time.time()\n","    epoch_train_loss = 0.0  # epoch 손실 합\n","    epoch_val_loss = 0.0    # epoch 손실 합\n","\n","    print('-------------')\n","    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","    print('-------------')\n","\n","    # 에폭별 훈련 및 검증 반복문\n","    for phase in ['train', 'val']:\n","      if phase == 'train':\n","        net.train()       # 모델을 훈련 모드로\n","        scheduler.step()  # 최적화 스케쥴러 갱신\n","        optimizer.zero_grad()\n","        print('（train）')\n","\n","      else:\n","        if((epoch+1) % 5 == 0):\n","          net.eval()      # 모델을 검증 모드로\n","          print('-------------')\n","          print('（val）')\n","        else:\n","          # 검증은 다섯 번 중 한 번만 수행\n","          continue\n","      # 데이터로더에서 미니 배치씩 꺼내서 반복\n","      count = 0  # 멀티플 미니 배치\n","      for imges, anno_class_imges in dataloaders_dict[phase]:\n","        # 미니 배치 크기가 1이면 배치 정규화에서 오류가 발생하여 피함.\n","        if imges.size()[0] == 1:\n","          continue\n","\n","        # GPU를 사용할 수 있으면 GPU에 데이터를 보낸다\n","        imges = imges.to(device)\n","        anno_class_imges = anno_class_imges.to(device)\n","\n","        # 멀티플 미니 배치로 파라미터 갱신\n","        if (phase == 'train') and (count == 0):\n","          optimizer.step()\n","          optimizer.zero_grad()\n","          count = batch_multiplier\n","\n","        # 순전파 계산\n","        with torch.set_grad_enabled(phase == 'train'):\n","          outputs = net(imges)\n","          loss = criterion(outputs, anno_class_imges.long()) / batch_multiplier\n","\n","          # 훈련시에는 역전파\n","          if phase == 'train':\n","            loss.backward()  # 경사 계산\n","            count -= 1       # 멀티플 미니 배치\n","\n","            if (iteration % 10 == 0):  # 10iter에 한 번 손실 표시\n","              t_iter_finish = time.time()\n","              duration = t_iter_finish - t_iter_start\n","              print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(iteration, loss.item()/batch_size*batch_multiplier, duration))\n","              t_iter_start = time.time()\n","\n","            epoch_train_loss += loss.item() * batch_multiplier\n","            iteration += 1\n","\n","          # 검증\n","          else:\n","            epoch_val_loss += loss.item() * batch_multiplier\n","    # 에폭의 페이즈별 손실과 정답률\n","    t_epoch_finish = time.time()\n","    print('-------------')\n","    print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(epoch+1, epoch_train_loss/num_train_imgs, epoch_val_loss/num_val_imgs))\n","    print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n","    t_epoch_start = time.time()\n","\n","    # 로그 저장\n","    log_epoch = {'epoch': epoch+1, 'train_loss': epoch_train_loss / num_train_imgs, 'val_loss': epoch_val_loss/num_val_imgs}\n","    logs.append(log_epoch)\n","    df = pd.DataFrame(logs)\n","    df.to_csv(\"log_output.csv\")\n","\n","\n","  # 마지막 네트워크 저장\n","  torch.save(net.state_dict(), 'weights/pspnet50_' + str(epoch+1) + '.pth')"],"metadata":{"id":"LEB1LL3w75B-","executionInfo":{"status":"ok","timestamp":1664249040275,"user_tz":-540,"elapsed":424,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# 학습 및 검증 시행\n","num_epochs = 30\n","train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs=num_epochs)"],"metadata":{"id":"vsCRSzpg-Mew"},"execution_count":null,"outputs":[]}]}