{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMM1NL8aCoL98VF9eprHtgi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5feab1e2c31742e5897c6570d08e8489":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5afc74d3b99341888e4967c389e701b7","IPY_MODEL_6a582b826a2641489a97ab4c078ef336","IPY_MODEL_25a0b7c6f810499d8dc5e40e6137f43e"],"layout":"IPY_MODEL_e4947d9efa5a4aa1b965aa4831871f6e"}},"5afc74d3b99341888e4967c389e701b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87ce6c44c9fd49cdafec556d305aef85","placeholder":"​","style":"IPY_MODEL_311d9e63b4c640abbcc0c3502d4c0186","value":"100%"}},"6a582b826a2641489a97ab4c078ef336":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dcddc6d492e4e509cee902c2c4395c9","max":553433881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cac2c682bd004befa026b9a6247b03b9","value":553433881}},"25a0b7c6f810499d8dc5e40e6137f43e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d2417c3ff6e48479fc0b720dd59bef8","placeholder":"​","style":"IPY_MODEL_dddc8cf2e96c48bcb8bbbe122ee54b07","value":" 528M/528M [00:06&lt;00:00, 121MB/s]"}},"e4947d9efa5a4aa1b965aa4831871f6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87ce6c44c9fd49cdafec556d305aef85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"311d9e63b4c640abbcc0c3502d4c0186":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dcddc6d492e4e509cee902c2c4395c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cac2c682bd004befa026b9a6247b03b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d2417c3ff6e48479fc0b720dd59bef8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dddc8cf2e96c48bcb8bbbe122ee54b07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from torchvision import models\n","\n","from tqdm import tqdm"],"metadata":{"id":"NxsouAdKd0Df","executionInfo":{"status":"ok","timestamp":1663150018809,"user_tz":-540,"elapsed":315,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)"],"metadata":{"id":"fLRDd9KVd24H","executionInfo":{"status":"ok","timestamp":1663150095927,"user_tz":-540,"elapsed":288,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/Rope-player/pytorch_advanced.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxW6y6ZyeFRY","executionInfo":{"status":"ok","timestamp":1663150093701,"user_tz":-540,"elapsed":392,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"01494b74-9ad5-47c5-a8f0-bb099333208c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'pytorch_advanced' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["%cd \"pytorch_advanced\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7Wrh65AeEf3","executionInfo":{"status":"ok","timestamp":1663150097587,"user_tz":-540,"elapsed":2,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"f2ef1305-f41a-410e-f31e-95f3e203c8e0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/pytorch_advanced\n"]}]},{"cell_type":"code","source":["%cd \"1_image_classification\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzYCVejzeJX_","executionInfo":{"status":"ok","timestamp":1663150104907,"user_tz":-540,"elapsed":2,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"d46fd1da-15cf-4622-b379-45bf22a368c7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/pytorch_advanced/1_image_classification\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JA-Na-n_eLGX","executionInfo":{"status":"ok","timestamp":1663150111413,"user_tz":-540,"elapsed":873,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"051a4e2c-8613-48fe-aa4c-519218df393a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["1-1_load_vgg.ipynb\n","1-1_load_vgg_on_GoogleColab.ipynb\n","1-3_transfer_learning.ipynb\n","1_3_transfer_learning_on_GoogleColab.ipynb\n","1-5_fine_tuning.ipynb\n","\u001b[0m\u001b[01;34mdata\u001b[0m/\n","make_folders_and_data_downloads.ipynb\n","\u001b[01;34mutils\u001b[0m/\n"]}]},{"cell_type":"markdown","source":["# **파인튜닝**"],"metadata":{"id":"QaQBKDKbb8aE"}},{"cell_type":"markdown","source":["- 파인튜닝: 출력층 등을 변경한 모델을 학습된 모델을 기반으로 구축한 후 직접 준비한 데이터로 신경망 모델의 결함 파라미터를 학습시키는 방법."],"metadata":{"id":"AfFWIk0Kb_Ms"}},{"cell_type":"markdown","source":["파인튜닝은 전이학습과는 다르게 출력층 및 그 인접 부분뿐만 아니라 모든 층의 파라미터를 다시 학습시킴. (그래도 입력층에 가까운 파라미터는 학습률을 적게, 출력층에 가까운 파라미터는 학습률을 크게 설정함.)"],"metadata":{"id":"RBAhs4HwcQmL"}},{"cell_type":"markdown","source":["## 데이터셋과 데이터로더 작성"],"metadata":{"id":"4WKseXIpcu0w"}},{"cell_type":"markdown","source":["데이터셋 및 데이터로더 작성 방법은 전이학습과 동일하게 함."],"metadata":{"id":"QVZiOnp-czR3"}},{"cell_type":"code","source":["# 전이학습 실습하면서 작성한 클래스\n","from utils.dataloader_image_classification import ImageTransform, make_datapath_list, HymenopteraDataset\n","\n","# 개미와 벌의 화상 파일 경로 리스트 작성\n","train_list = make_datapath_list(phase = \"train\")\n","val_list = make_datapath_list(phase = \"val\")\n","\n","\n","# 데이터셋 작성\n","size = 224\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","train_dataset = HymenopteraDataset(\n","    file_list=train_list, transform = ImageTransform(size, mean, std), phase='train')\n","\n","val_dataset = HymenopteraDataset(\n","    file_list=val_list, transform = ImageTransform(size, mean, std), phase='val')\n","\n","# 데이터로더 작성\n","batch_size = 32\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle = True)\n","\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle = False)\n","\n","# 사전 객체에 정리\n","dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5IlHWAXdDG5","executionInfo":{"status":"ok","timestamp":1663150285581,"user_tz":-540,"elapsed":321,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"13161d9b-a3d6-45b0-f445-56b32383cc06"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["./data/hymenoptera_data/train/**/*.jpg\n","./data/hymenoptera_data/val/**/*.jpg\n"]}]},{"cell_type":"markdown","source":["## 네트워크 모델 작성"],"metadata":{"id":"UEHxbRE1e4Vt"}},{"cell_type":"markdown","source":["네트워크 모델도 전이학습시 것과 동일"],"metadata":{"id":"ESkyoO8Le83O"}},{"cell_type":"code","source":["# VGG16 모델의 인스턴스 생성\n","use_pretrained = True\n","net = models.vgg16(pretrained = use_pretrained)\n","\n","# VGG-16의 마지막 출력층의 출력 유닛을 개미와 벌 두 개로 지정\n","net.classifier[6] = nn.Linear(in_features = 4096, out_features = 2)\n","\n","# 훈련모드로 설정\n","net.train()\n","\n","print('네트워크 설정 완료: 학습된 가중치를 읽어들여 훈련 모드로 설정했습니다.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179,"referenced_widgets":["5feab1e2c31742e5897c6570d08e8489","5afc74d3b99341888e4967c389e701b7","6a582b826a2641489a97ab4c078ef336","25a0b7c6f810499d8dc5e40e6137f43e","e4947d9efa5a4aa1b965aa4831871f6e","87ce6c44c9fd49cdafec556d305aef85","311d9e63b4c640abbcc0c3502d4c0186","1dcddc6d492e4e509cee902c2c4395c9","cac2c682bd004befa026b9a6247b03b9","7d2417c3ff6e48479fc0b720dd59bef8","dddc8cf2e96c48bcb8bbbe122ee54b07"]},"id":"-b3IXyate8WL","executionInfo":{"status":"ok","timestamp":1663150418493,"user_tz":-540,"elapsed":8439,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"8152d0c8-d314-47cf-98e1-43925e31fc4a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/528M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5feab1e2c31742e5897c6570d08e8489"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["네트워크 설정 완료: 학습된 가중치를 읽어들여 훈련 모드로 설정했습니다.\n"]}]},{"cell_type":"markdown","source":["## 손실함수 정의"],"metadata":{"id":"qcbxOTC1fWdA"}},{"cell_type":"markdown","source":["마찬가지로 전이학습때의 것. 크로스엔트로피 오차 함수를 사용하여 손실함수 정의."],"metadata":{"id":"SJ0TrfC6favo"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"wB6NQjfefVzo","executionInfo":{"status":"ok","timestamp":1663150480208,"user_tz":-540,"elapsed":787,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## 최적화 방법 설정"],"metadata":{"id":"WyqWqeCwfmkE"}},{"cell_type":"markdown","source":["전이학습 때와는 다르게 모든 층의 파라미터를 학습할 수 있도록 옵티마이저를 설정.\n","\n","먼저 각 층의 학습률을 바꿀수 있도록  파라미터 설정. VGG16의 전반부 `features` 모듈의 파라미터를 `update_param_names_1` 변수에, 후반부 classifier 모듈 중 초음 두개의 전결합층(Full-Connected Layer) 파라미터를 `update_param_names_2` 변수에, 교체한 마지막 전결합층 파라미터를 `update_param_names_2` 변수에 저장. (각각 다른 학습률 적용 가능.)"],"metadata":{"id":"ii3TYPSyf2fj"}},{"cell_type":"code","source":["# 파인튜닝으로 학습할 파라미터를 각 변수에 저장.\n","params_to_update_1 = []\n","params_to_update_2 = []\n","params_to_update_3 = []\n","\n","# 학습시킬 층의 파라미터명 지정\n","update_param_names_1 = [\"features\"]\n","update_param_names_2 = [\"classifier.0.weight\",\n","                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n","update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n","\n","# 파라미터를 각 리스트에 저장\n","for name, param in net.named_parameters():\n","    if update_param_names_1[0] in name:\n","        param.requires_grad = True\n","        params_to_update_1.append(param)\n","        print(\"params_to_update_1에 저장：\", name)\n","\n","    elif name in update_param_names_2:\n","        param.requires_grad = True\n","        params_to_update_2.append(param)\n","        print(\"params_to_update_2에 저장：\", name)\n","\n","    elif name in update_param_names_3:\n","        param.requires_grad = True\n","        params_to_update_3.append(param)\n","        print(\"params_to_update_3에 저장：\", name)\n","\n","    else:\n","        param.requires_grad = False   # 경사가 없으면 이곳으로 옴.\n","        print(\"경사 계산 없음. 학습하지 않았음：\", name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQ9RnkH0gzQe","executionInfo":{"status":"ok","timestamp":1663151005387,"user_tz":-540,"elapsed":290,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"a7d3ee91-dc77-44af-d843-2cfd933ed67a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["params_to_update_1에 저장： features.0.weight\n","params_to_update_1에 저장： features.0.bias\n","params_to_update_1에 저장： features.2.weight\n","params_to_update_1에 저장： features.2.bias\n","params_to_update_1에 저장： features.5.weight\n","params_to_update_1에 저장： features.5.bias\n","params_to_update_1에 저장： features.7.weight\n","params_to_update_1에 저장： features.7.bias\n","params_to_update_1에 저장： features.10.weight\n","params_to_update_1에 저장： features.10.bias\n","params_to_update_1에 저장： features.12.weight\n","params_to_update_1에 저장： features.12.bias\n","params_to_update_1에 저장： features.14.weight\n","params_to_update_1에 저장： features.14.bias\n","params_to_update_1에 저장： features.17.weight\n","params_to_update_1에 저장： features.17.bias\n","params_to_update_1에 저장： features.19.weight\n","params_to_update_1에 저장： features.19.bias\n","params_to_update_1에 저장： features.21.weight\n","params_to_update_1에 저장： features.21.bias\n","params_to_update_1에 저장： features.24.weight\n","params_to_update_1에 저장： features.24.bias\n","params_to_update_1에 저장： features.26.weight\n","params_to_update_1에 저장： features.26.bias\n","params_to_update_1에 저장： features.28.weight\n","params_to_update_1에 저장： features.28.bias\n","params_to_update_2에 저장： classifier.0.weight\n","params_to_update_2에 저장： classifier.0.bias\n","params_to_update_2에 저장： classifier.3.weight\n","params_to_update_2에 저장： classifier.3.bias\n","params_to_update_3에 저장： classifier.6.weight\n","params_to_update_3에 저장： classifier.6.bias\n"]}]},{"cell_type":"markdown","source":["이어서 각 파라미터에 최적화 방법 설정. 모멘텀 SGD를 사용.\n","\n","`params_to_update_1`의 학습률을 **1e-4**로, `params_to_update_2`는 **5e-4**, `params_to_update_2`은 **1e-3**.\n","\n","momentum은 모두 **0.9**"],"metadata":{"id":"L7onTakyhpMW"}},{"cell_type":"markdown","source":[],"metadata":{"id":"ywMq2ClUiK8r"}},{"cell_type":"code","source":["# 최적화 방법 설정\n","optimizer = optim.SGD([\n","    {'params': params_to_update_1, 'lr': 1e-4},\n","    {'params': params_to_update_2, 'lr': 5e-4},\n","    {'params': params_to_update_3, 'lr': 1e-3}\n","], momentum=0.9)\n","\n","# [] 밖에 작성한 파라미터는 모든 params에 동일하게 적용 됨. momentum 값은 모두 동일하기에 [] 밖에 작성."],"metadata":{"id":"c0R6kvd7iMkV","executionInfo":{"status":"ok","timestamp":1663153504527,"user_tz":-540,"elapsed":505,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## 학습 및 검증 실시"],"metadata":{"id":"mWF3aAEhij1Q"}},{"cell_type":"markdown","source":["모델을 학습시키는 `train_model` 함수 정의."],"metadata":{"id":"1zkg61DXjCDG"}},{"cell_type":"code","source":["def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","\n","  # GPU가 사용 가능한지 확인 사용가능하면 device 변수에 'gpu'가 저장되ㅗ 아니라면 'cpu'가 저장됨\n","  # device 변수를 통해 네트워크 모델, 모델에 입력할 데이터, 라벨 데이터를 GPU에 전송\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(\"사용 장치:\", device)\n","\n","  net.to(device)\n","\n","  # 네트워크가 어느 정도 고정되면 고속화 시킴.\n","  torch.backends.cudnn.benchmark = True\n","\n","\n","  # 에폭 반복문\n","  for epoch in range(num_epochs):\n","    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","    print('-------------')\n","\n","    # 에폭별 훈련 및 검증 반복문\n","    for phase in ['train', 'val']:\n","      if phase == 'train':\n","        net.train()  # 모델을 훈련 모드로\n","      else:\n","        net.eval()   # 모델을 검증 모드로\n","\n","        epoch_loss = 0.0   # 에폭 손실 합\n","        epoch_corrects = 0 # 에폭 정답 수\n","\n","        # 학습하지 않을 때의 검증 성능을 확인하기 위해 에폭이 0일때 훈련 생략\n","        if (epoch == 0) and (phase == 'train'):\n","          continue\n","\n","\n","        # 데이터로더에서 미니 배치를 꺼내서 루프\n","        for inputs, labels in tqdm(dataloaders_dict[phase]):\n","\n","          # GPU가 사용가능하면 GPU에 데이터 전송\n","          inputs = inputs.to(device)\n","          labels = labels.to(device)\n","\n","          # 옵티마이저 초기화\n","          optimizer.zero_grad()\n","\n","          # 순전파 계산\n","          with torch.set_grad_enabled(phase == 'train'):\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)  # 손실 계산\n","            _, preds = torch.max(outputs, 1)   # 라벨 예측\n","\n","            # 훈련 시에는 오차 역전파\n","            if phase == 'train':\n","              loss.backward()\n","              optimizer.step()\n","\n","            # 결과 계산\n","            # 손실의 합계 갱신\n","            epoch_loss += loss.item() * inputs.size(0)  \n","            # 정답의 합계 갱신\n","            epoch_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","        epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n","\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))"],"metadata":{"id":"-oYpOZhXilsI","executionInfo":{"status":"ok","timestamp":1663153471229,"user_tz":-540,"elapsed":284,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# 학습 및 검증 시행\n","\n","num_epochs=2\n","train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxaTJGTprBaO","executionInfo":{"status":"ok","timestamp":1663153704194,"user_tz":-540,"elapsed":195885,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"eabbf29b-e831-4283-a3b4-1b30f0e70d73"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["사용 장치: cpu\n","Epoch 1/2\n","-------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [01:37<00:00, 19.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 0.7704 Acc: 0.4444\n","Epoch 2/2\n","-------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [01:38<00:00, 19.67s/it]"]},{"output_type":"stream","name":"stdout","text":["val Loss: 0.7704 Acc: 0.4444\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## 네트워크 저장 및 로드"],"metadata":{"id":"7C9kesWOrNbR"}},{"cell_type":"markdown","source":["저장할 경우에는 네트워크 모델의 `net`변수를 `.state_dict()`를 활용해 파라미터를 사전형 변수로 꺼낸 후 `torch.save()`로 저장. `save_path` 변수는 저장할 경로를 지정."],"metadata":{"id":"7Hs5hATxrO_p"}},{"cell_type":"code","source":["save_path = './weights_fine_tuning.pth'\n","torch.save(net.state_dict(), save_path) # 저장할 파라미터, 경로"],"metadata":{"id":"-0Zd9eGGrl3Y","executionInfo":{"status":"ok","timestamp":1663153830033,"user_tz":-540,"elapsed":2468,"user":{"displayName":"J지원","userId":"16050027595319260781"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["불러오기를 할 경우에는 `torch.load()`로 사전형 객체를 로드하여 `net.state_dict()`에 저장.\n","\n","GPU상에 저장된 파일을 CPU에 로드할 때는 `map_location`을 사용해야 함.  "],"metadata":{"id":"GRT19Rw_ryyk"}},{"cell_type":"code","source":["load_path = './weights_fine_tuning.pth'\n","load_weights = torch.load(load_path)\n","net.load_state_dict(load_weights)\n","\n","# GPU에 저장된 가중치를 CPU에 로드하는 경우\n","load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\n","net.load_state_dict(load_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8qT8TC3sRBP","executionInfo":{"status":"ok","timestamp":1663153832460,"user_tz":-540,"elapsed":974,"user":{"displayName":"J지원","userId":"16050027595319260781"}},"outputId":"11fe3927-44d0-4aba-d860-9a0ec2dd792a"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["파인튜닝을 사용하여 소량의 데이터로도 높은 딥러닝 성능을 낼 수 있음."],"metadata":{"id":"cIVunVp3saIC"}}]}