{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Rope-player/pytorch_advanced.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQXkaey1M8WS",
        "outputId": "1bd9330b-0ce5-47cb-81eb-39a49f521942"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch_advanced'...\n",
            "remote: Enumerating objects: 548, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 548 (delta 5), reused 162 (delta 0), pack-reused 374\u001b[K\n",
            "Receiving objects: 100% (548/548), 50.13 MiB | 23.01 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"pytorch_advanced\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzk03MB2M-y9",
        "outputId": "229762ad-76c1-4868-b0e9-80eac6100b99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_advanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"2_objectdetection\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYc3FVtPM-4l",
        "outputId": "ccbe6119-ddfe-4d4a-96ac-ce9407359d0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_advanced/2_objectdetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kN7NiQrIL_by"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from utils.match import match"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SSD의 손실함수 클래스 MultiBoxLoss 구현"
      ],
      "metadata": {
        "id": "wQh1oI_nMD1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiBoxLoss(nn.Module):  # SSD의 손실함수 클래스 \n",
        "  def __init__(self, jaccard_thresh=0.5, neg_pos=3, device='cpu'):\n",
        "    super(MultiBoxLoss, self).__init__()\n",
        "    self.jaccard_thresh = jaccard_thresh  # 0.5 match 함수의 jaccard 계수의 임계치\n",
        "    self.negpos_ratio = neg_pos           # 3:1 Hard Negative Mining의 음과 양의 비율\n",
        "    self.device = device                  # CPU와 GPU 중 어느것으로 계산하는가\n",
        "\n",
        "  def forward(self, predictions, targets):\n",
        "    # 손실함수 계산\n",
        "    # Parameters\n",
        "    #   predictions : SSD net의 훈련 시 출력(tuple) - (loc=torch.Size([num_batch, 8732, 4]), conf=torch.Size([num_batch, 8732, 21]), dbox_list=torch.Size [8732,4])。\n",
        "    #   targets : [num_batch, num_objs, 5] - 5는 정답인 어노테이션 정보[xmin, ymin, xmax, ymax, label_ind]\n",
        "    #\n",
        "    # Returns\n",
        "    #   loss_l : 텐서 - loc의  손실 값\n",
        "    #   loss_c : 텐서 - conf의 손실 값\n",
        "\n",
        "    # SSD 모델의 출력이 튜플로 되어 있어 개별적으로 분리\n",
        "    loc_data, conf_data, dbox_list = predictions\n",
        "\n",
        "    # 요소 수 파악\n",
        "    num_batch = loc_data.size(0)     # 미니 배치 크기\n",
        "    num_dbox = loc_data.size(1)      # DBox   = 8732\n",
        "    num_classes = conf_data.size(2)  # 클래스 = 21\n",
        "\n",
        "    # 손실 계산에 사용할 것을 저장하는 변수 생성\n",
        "    # conf_t_label：각 DBox에 가장 가까운 정답 BBox의 라벨 저장\n",
        "    # loc_t:        각 DBox에 가장 가까운 정답 BBox의 위치 정보 저장\n",
        "    conf_t_label = torch.LongTensor(num_batch, num_dbox).to(self.device)\n",
        "    loc_t = torch.Tensor(num_batch, num_dbox, 4).to(self.device)\n",
        "\n",
        "    # loc_t와 conf_t_label에 DBox와 정답 어노테이션 targets을 match한 결과 덮어 쓰기\n",
        "    for idx in range(num_batch):  # 미니 배치 루프\n",
        "      # 현재 미니 배치의 정답 어노테이션 BBox와 라벨 취득\n",
        "      truths = targets[idx][:, :-1].to(self.device)  # BBox\n",
        "      # 라벨 [물체1 라벨, 물체2 라벨, ...]\n",
        "      labels = targets[idx][:, -1].to(self.device)\n",
        "\n",
        "      # 디폴트박스를 새로운 변수로 준비\n",
        "      dbox = dbox_list.to(self.device)\n",
        "\n",
        "      # match 함수를 실행하여 loc_t와 conf_t_label 내용 갱신\n",
        "      # loc_t:        각DBox에 가장 가까운 정답 BBox 위치 정보가 덮어써 짐\n",
        "      # conf_t_label：각DBox에 가장 가까운 정답 BBox 라벨이 덮어써 짐\n",
        "      # 단 가장 가까운 BBox 와의 jaccard overlap이 0.5보다 큰 경우 정답 BBox의 라벨 conf_t_label은 배경 클래스0으로 한다.\n",
        "\n",
        "      variance = [0.1, 0.2]\n",
        "      # variance는 DBox에서 BBox로 보정 계산할 때 사용하는 식의 계수\n",
        "      match(self.jaccard_thresh, truths, dbox, variance, labels, loc_t, conf_t_label, idx)\n",
        "\n",
        "    # 위치 손실：loss_l을 계산\n",
        "    # Smooth L1 함수로 각 손실 계산. 단 물체를 발견한 DBox의 오프셋만 계산\n",
        "    # 물체를 감지한 BBox를 꺼내는 마스크 작성\n",
        "    pos_mask = conf_t_label > 0  # torch.Size([num_batch, 8732])\n",
        "\n",
        "    # pos_mask를 loc_data 크기로 변형\n",
        "    pos_idx = pos_mask.unsqueeze(pos_mask.dim()).expand_as(loc_data)\n",
        "\n",
        "    # Positive DBox의 loc_data와 지도 데이터 loc_t 취득\n",
        "    loc_p = loc_data[pos_idx].view(-1, 4)\n",
        "    loc_t = loc_t[pos_idx].view(-1, 4)\n",
        "\n",
        "    # 물체를 발견한 Positive DBox의 오프셋 정보 loc_t의 손실(오차)을 계산\n",
        "    loss_l = F.smooth_l1_loss(loc_p, loc_t, reduction='sum')\n",
        "\n",
        "    # 클래스 예측의 손실：loss_c 계산\n",
        "    # 교차 엔트로피 오차 함수로 손실 계산, 단 배경 클래스가 정답인 DBox가 압도적으로 많지 않으므로 Hard Negative Mining을 실시하요 물체 발견 DBox및 배경 클래스 DBox의 비율이 1:3이 되도록 함\n",
        "    # 배경 클래스 DBox로 예상한 것 중 손실이 적은 것은 클래스 예측 손실에서 제외\n",
        "\n",
        "    batch_conf = conf_data.view(-1, num_classes)\n",
        "\n",
        "    # 클래스 예측의 손실 함수계산(reduction='none'으로 하여 합을 취하지 않고 차원을 보존)\n",
        "    loss_c = F.cross_entropy(batch_conf, conf_t_label.view(-1), reduction='none')\n",
        "\n",
        "    # Negative DBox 중 Hard Negative Mining으로 추출하는 것을 구하는 마스크 작성\n",
        "\n",
        "    # 물체를 발견한 Positive DBox의 손실을 0으로.\n",
        "    # (주의) 물체는 label이 1 이상 . 라벨 0은 배경을 의미.\n",
        "    num_pos = pos_mask.long().sum(1, keepdim=True)  # 미니배치별 물체 클래스의 예측 수\n",
        "    loss_c = loss_c.view(num_batch, -1)             # torch.Size([num_batch, 8732])\n",
        "    loss_c[pos_mask] = 0                            # 물체를 발견한 DBox의 손실을 0으로\n",
        "\n",
        "    # Hard Negative Mining 실시\n",
        "    # 각 DBox 손실의 크기 loss_c 순위 idx_rank를 구함.\n",
        "    _, loss_idx = loss_c.sort(1, descending=True)\n",
        "    _, idx_rank = loss_idx.sort(1)\n",
        "\n",
        "    # 위 두 줄의 요점은 각 DBox에 대해 손실 크기가 몇 번째 정보인지 정보를 변수 idx_rank로 빠르게 얻는 코드.\n",
        "    # DBOX의 손실 값이 큰 쪽부터 내림차순으로 정렬하여 DBox의 내림차순의 index를 loss_idx에 저장. 손실크기 loss_c의 순위 idx_rank를 구한다.\n",
        "    # 내림차순이 된 배열 index인 loss_idx를 0부터 8732 까지 오름차순으로 다시 정렬 해야 함.\n",
        "    # 몇 번째 loss_idx의 인덱를 취할지 나타내는 것이 idx_rank임.\n",
        "    # 예를 들어 idx_rank 요소의0번째 = idx_rank[0]을 구하는 것은 loss_idx의 값이 0인 요소, loss_idx[?}=0 의 ?는 몇 번째를 구할 것인지가 됨. 여기서 ? = idx_rank[0]\n",
        "    # loss_idx[?]=0의 0은 원래 loss_c의 요소 0번째라는 의미임.\n",
        "    # 즉 '?'는 원래 loss_c의 요소 0번째는 내림차순으로 정렬된 loss_idx의 몇 번째인가를 구하는 것\n",
        "    # ? = idx_rank[0]은 loss_c의 요소 0번째가 내림차순으로 몇 번째인가를 나타냄.\n",
        "\n",
        "    # 배경 DBox의 수 num_neg를 구함. HardNegative Mining으로 물체 발견 DBox의 수 num_pos의 3배(self.negpos_ratio 배)로 함.\n",
        "    # DBox의 수를 초과한 경우에는 DBox의 수를 상한으로 함.\n",
        "    num_neg = torch.clamp(num_pos*self.negpos_ratio, max=num_dbox)\n",
        "\n",
        "    # idx_rank에 각 DBox의 손실 크기가 위에서부터 몇 번째인지 저장되었다.\n",
        "    # 배경 DBox의 수 num_neg보다 순위가 낮은(손실이 큰) DBox를 취하는 마스크\n",
        "    # torch.Size([num_batch, 8732])\n",
        "    neg_mask = idx_rank < (num_neg).expand_as(idx_rank)\n",
        "\n",
        "    # (종료) 여기부터 Negative DBox 중 Hard Negative Mining으로 추출할 것을 구하는 마스크 작성\n",
        "\n",
        "    # 마스크 모양을 고쳐 conf_data에 맞춤\n",
        "    # pos_idx_mask는 Positive DBox의 conf를 꺼내는 마스크\n",
        "    # neg_idx_mask는 Hard Negative Mining으로 추출한 Negative DBox의 conf를 꺼내는 마스크\n",
        "    # pos_mask：torch.Size([num_batch, 8732]) → pos_idx_mask：torch.Size([num_batch, 8732, 21])\n",
        "    pos_idx_mask = pos_mask.unsqueeze(2).expand_as(conf_data)\n",
        "    neg_idx_mask = neg_mask.unsqueeze(2).expand_as(conf_data)\n",
        "\n",
        "    \n",
        "    # conf_data에서 pos와 neg만 꺼내서 conf_hnm으로 한다. 형태는 torch.Size([num_pos+num_neg, 21])\n",
        "    conf_hnm = conf_data[(pos_idx_mask+neg_idx_mask).gt(0)].view(-1, num_classes)\n",
        "    # gt는 greater than (>)의 약칭. mask가 1인 index를 꺼냄.\n",
        "    # pos_idx_mask + neg_idx_mask는 덧셈이지만 index로 mask를 정리 하는 역할.\n",
        "    # pos든 neg든 마스크가 1인 것을 더해 하나의 리스트로 만들어 이를 gt로 취득\n",
        "\n",
        "    # 지도 데이터인 conf_t_label에서 pos와 neg만 꺼내 conf_t_label_hnm으로 torch.Size([pos + neg])의 형태가 됨.\n",
        "    conf_t_label_hnm = conf_t_label[(pos_mask+neg_mask).gt(0)]\n",
        "\n",
        "    # confidence의 손실함수 계산(요소의 합계 = sum을 구함)\n",
        "    loss_c = F.cross_entropy(conf_hnm, conf_t_label_hnm, reduction='sum')\n",
        "\n",
        "    # 물체를 발견한 BBox의 수 N(전체 미니 배치의 합)으로 손실을 나눔.\n",
        "    N = num_pos.sum()\n",
        "    loss_l /= N\n",
        "    loss_c /= N\n",
        "\n",
        "    return loss_l, loss_c\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nJBuhSnlNOiQ"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}